{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (15 points)\n",
    "Select the dataset:\n",
    "- [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "Extra credit for the dataset below\n",
    "- [ImageNet](http://www.image-net.org/) *\n",
    "- [300-W](https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/)\n",
    "- [IMDB-WIKI](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/) *\n",
    "- [UTKFace](https://susanqq.github.io/UTKFace/)\n",
    "- Any other, but in this case, please check with me. For example, something from [here](https://huggingface.co/datasets?task_categories=task_categories:image-classification) or [here](https://www.tensorflow.org/datasets/catalog/overview).\n",
    "\n",
    "<i>*since the dataset is very large, you can take a part of it</i>\n",
    "\n",
    "Choose an architecture:\n",
    "- VGGNet\n",
    "- Inception (v1-v4)\n",
    "- Inception-ResNet-v2\n",
    "- ResNet\n",
    "- Xception\n",
    "- Any other, but in this case, please coordinate with me\n",
    "\n",
    "Solve a classification or regression problem with the selected architecture for the selected dataset. Implement a neural network from scratch, you cannot take a ready-made one.\n",
    "\n",
    "It is highly recommended to train on GPU. If you do not have a CUDA-compatible video card, use [Google Collaboratory](https://colab.research.google.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (2.19.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: setuptools in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: optree in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: namex in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (3.20.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: matplotlib in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (3.9.4)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\адмін\\appdata\\roaming\\python\\python39\\site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow \n",
    "%pip install matplotlib \n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(image, label):\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    image = tf.image.resize(image, (227, 227))\n",
    "    return image, label\n",
    "\n",
    "def get_data(train_images, train_labels, test_images, test_labels):\n",
    "    validation_images, validation_labels = train_images[:5000], train_labels[:5000]\n",
    "    train_images, train_labels = train_images[5000:], train_labels[5000:]\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "    validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
    "\n",
    "    train_ds = (train_ds\n",
    "                .map(process_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                #.shuffle(buffer_size=1000)\n",
    "                .batch(batch_size=32, drop_remainder=True)\n",
    "                .prefetch(tf.data.AUTOTUNE))\n",
    "    test_ds = (test_ds\n",
    "               .map(process_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "               #.shuffle(buffer_size=1000)\n",
    "               .batch(batch_size=32, drop_remainder=True)\n",
    "               .prefetch(tf.data.AUTOTUNE))\n",
    "    validation_ds = (validation_ds\n",
    "                     .map(process_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                     #.shuffle(buffer_size=1000)\n",
    "                     .batch(batch_size=32, drop_remainder=True)\n",
    "                     .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "    return train_ds, validation_ds, test_ds\n",
    "\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "train_ds, validation_ds, test_ds = get_data(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def residual_block(x, filters, stride=1):\n",
    "    shortcut = x\n",
    "\n",
    "    x = layers.Conv2D(filters, (3, 3), strides=stride, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, (3, 3), strides=1, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = layers.Conv2D(filters, (1, 1), strides=stride, padding=\"same\")(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def ResNet(input_size, output_size):\n",
    "    inputs = layers.Input(shape=input_size)\n",
    "    x = layers.Conv2D(64, (7, 7), strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=2, padding=\"same\")(x)\n",
    "\n",
    "    # Residual blocks\n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 64)\n",
    "    \n",
    "    x = residual_block(x, 128, stride=2)\n",
    "    x = residual_block(x, 128)\n",
    "\n",
    "    x = residual_block(x, 256, stride=2)\n",
    "    x = residual_block(x, 256)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(output_size, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m  14/1406\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56:24\u001b[0m 2s/step - accuracy: 0.1221 - loss: 2.4797"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 17\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet(input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m227\u001b[39m, \u001b[38;5;241m227\u001b[39m, \u001b[38;5;241m3\u001b[39m), output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[0;32m     13\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"best_resnet_model.keras\"\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model = ResNet(input_size=(227, 227, 3), output_size=10)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=40,\n",
    "    callbacks=[checkpoint_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using colab with gpu for fast training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 643ms/step - accuracy: 0.8352 - loss: 1.0235\n",
      "\n",
      "Best Model Test Accuracy: 0.8361, Test Loss: 1.0322\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model(checkpoint_path)\n",
    "\n",
    "test_loss, test_accuracy = best_model.evaluate(test_ds)\n",
    "print(f\"\\nBest Model Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T10:17:28.957354Z",
     "start_time": "2020-03-30T10:17:28.940323Z"
    }
   },
   "source": [
    "### Task 1 (alternative) (15 points + bonus on the exam :))\n",
    "\n",
    "Choose something from the list:\n",
    "- Solve the problem of finding objects in an image:\n",
    "    - [Faces](https://www.tensorflow.org/datasets/catalog/wider_face)\n",
    "    - [Traffic objects](https://www.tensorflow.org/datasets/catalog/kitti)\n",
    "    - Something [from here](https://huggingface.co/datasets?task_categories=task_categories:object-detection&sort=downloads)\n",
    "    - Your choice\n",
    "- Semantic segmentation:\n",
    "    - [MRI brain scans](https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation)\n",
    "    - [Traffic objects](https://www.tensorflow.org/datasets/catalog/kitti)\n",
    "    - Something [from here](https://huggingface.co/datasets?task_categories=task_categories:image-segmentation&sort=downloads)\n",
    "    - Your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (15 points)\n",
    "Prepare your trained model for deployment:\n",
    "- **(5 points)** Convert model to Tensorflow Lite or ONNX;\n",
    "- **(5 points)** Setup the inference API server using any web-framework (Flask, FastAPI, etc.).\n",
    "  The inference API must contain `/predict` endpoint, which accepts an image and returns model prediction;\n",
    "- **(5 points)** Create Docker image for the inference API.\n",
    "\n",
    "Prepare a report demonstrating the process of running and querying the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Convert to Tensorflow Lite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\0E46~1\\AppData\\Local\\Temp\\tmpio6xs8k0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\0E46~1\\AppData\\Local\\Temp\\tmpio6xs8k0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\0E46~1\\AppData\\Local\\Temp\\tmpio6xs8k0'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 227, 227, 3), dtype=tf.float32, name='input_layer_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1943334170112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334169056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334191696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334191872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334177072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334178304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334195040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334230848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334253136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334254192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334231552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334252960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334256304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334275552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943354937760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943354938816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943334276256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943354937584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943354959648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943354958768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943354980128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943354981184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943354978896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943354979952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355000608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943354999728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355016992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355018048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355015760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355016816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355047072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355046016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355080768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355080944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355062224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355063280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355107632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355107104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355083936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355082704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355127936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355128992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355126704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355127760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355148416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355149472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355146832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355148240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355170304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355169248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355212192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355212368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355193648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355194704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355215360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355214128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355257248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355257424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355238704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355239760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355260768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355286448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355302832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355303888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355289264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355302656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355330400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355344848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355305648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355327408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355364096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355364272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355345552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355346608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355380480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355380656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355365680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355367088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355417872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355416992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355434256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355435312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355433024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355434080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355450640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355449760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355479312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355480368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355478080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355479136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355489968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355488912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355517760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1943355517408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Model successfully converted to TensorFlow Lite format.\n"
     ]
    }
   ],
   "source": [
    "# Convert to Tensorflow Lite format\n",
    "\n",
    "model = tf.keras.models.load_model(\"best_resnet_model.keras\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"resnet_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model successfully converted to TensorFlow Lite format.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
